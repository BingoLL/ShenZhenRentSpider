# ShenZhenRentSpider
python3.5 + scrapy1.4 爬取房天下深圳租房信息
目前问题点：
1、爬取两个页面就断开

输入下列命令执行爬虫，并将爬取数据存入test.csv
scrapy crawl ftx -o test.csv


